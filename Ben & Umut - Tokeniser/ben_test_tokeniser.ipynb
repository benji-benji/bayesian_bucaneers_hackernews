{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7185a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b84e3366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total titles in DB: 4070444\n"
     ]
    }
   ],
   "source": [
    "# LOAD TITLES\n",
    "\n",
    "def load_titles(pg_url):\n",
    "    conn = psycopg2.connect(pg_url)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"\"\"\n",
    "        SELECT title FROM hacker_news.items\n",
    "        WHERE type = 'story' AND dead IS NOT TRUE and title IS NOT NULL\n",
    "    \"\"\")\n",
    "    titles = [row[0] for row in cur.fetchall()]\n",
    "    conn.close()\n",
    "    return titles\n",
    "\n",
    "all_titles = load_titles(\"postgresql://sy91dhb:g5t49ao@178.156.142.230:5432/hd64m1ki\")\n",
    "print(f\"Total titles in DB: {all_titles.__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b36f7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\"', 'what', 'may', 'happen', 'in', 'the', 'next', 'hundr', 'year', '\"', ',', 'from', 'c', '.', '1900'], ['get', 'start', 'with', 'javascript', 'unit', 'test'], ['armstrong', ',', 'the', 'django', '-', 'base', 'and', 'open', '-', 'sourc', 'news', 'cm', ',', 'is', 'now', 'releas'], ['whi', 'web', 'review', 'make', 'up', 'bad', 'thing'], ['what', 'is', 'sopa', 'in', 'your', 'eye'], ['put', 'that', 'techcrunch', 'down'], ['get', 'better'], ['10', 'year', 'and', '320', 'million', 'unit', 'old', ':', 'appl', 'ipod'], ['ask', 'hn', ':', 'in', 'what', 'languag', 'should', 'i', 'invest', 'my', 'time', '?'], ['brain', 'scan', 'of', 'a', 'woman', 'dure', 'orgasm']]\n",
      "4070444\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "# Basic tokenizer using regex\n",
    "def tokenize(text: str, stemmer=stemmer) -> list:\n",
    "    \n",
    "    \n",
    "    #Keep punctuation as separate tokens\n",
    "    #This regex captures words and punctuation separately\n",
    "    #Lowercase and split on word boundaries\n",
    "    #\\w+ matches word characters, [^\\w\\s] matches punctuation\n",
    "\n",
    "    #Stem tokens if they are alphabetic\n",
    "    #Use Porter Stemmer for stemming\n",
    "    #If the token is not alphabetic, keep it as is\n",
    "    #This will stem words like \"running\" to \"run\", but keep numbers and punctuation intact\n",
    "    #\"Hello!\" → Tokens: [\"hello\", \"!\"]\n",
    "    #\"!?\" → Tokens: [\"!\", \"?\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text.lower())\n",
    "    \n",
    "    return [stemmer.stem(token) if token.isalpha() else token \n",
    "            for token in tokens]\n",
    "\n",
    "all_titles = load_titles(\"postgresql://sy91dhb:g5t49ao@178.156.142.230:5432/hd64m1ki\")\n",
    "tokenised_titles = [tokenize(title)\n",
    "                    for title in \n",
    "                    all_titles]\n",
    "print(tokenised_titles[:10])\n",
    "print(len(tokenised_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "086dceee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', 'what', 'may', 'happen', 'in', 'the', 'next', 'hundr', 'year', '\"', ',', 'from', 'c', '.', '1900']\n"
     ]
    }
   ],
   "source": [
    "def yield_tokens(texts):\n",
    "    for text in texts:\n",
    "        yield tokenize(text)\n",
    "        \n",
    "yielded_tokens = yield_tokens(all_titles)\n",
    "print(next(yielded_tokens))  # Print first tokenized title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbd12fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab_from_iterator(iterator, specials=['<pad>', '<unk>']):\n",
    "    counter = Counter()\n",
    "    for tokens in iterator:\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # Index-to-string list\n",
    "    itos = specials + [token for token, _ in counter.items()]\n",
    "    \n",
    "    # String-to-index dict with default to <unk>\n",
    "    stoi = defaultdict(lambda: specials.index('<unk>'), {token: idx for idx, token in enumerate(itos)})\n",
    "\n",
    "    # Return a callable vocab object similar to torchtext\n",
    "    class Vocab:\n",
    "        def __init__(self, stoi, itos):\n",
    "            self.stoi = stoi\n",
    "            self.itos = itos\n",
    "        def __call__(self, tokens):\n",
    "            return [self.stoi[token] for token in tokens]\n",
    "        def __getitem__(self, token):\n",
    "            return self.stoi[token]\n",
    "        def __len__(self):\n",
    "            return len(self.itos)\n",
    "\n",
    "    return Vocab(stoi, itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65692876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_titles(titles, vocab):\n",
    "    token_ids = [\n",
    "        torch.tensor(vocab(tokenize(title)), dtype=torch.long)\n",
    "        for title in titles\n",
    "    ]\n",
    "    return pad_sequence(token_ids, batch_first=True, padding_value=vocab['<pad>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f609d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline\n",
    "def main(pg_url):\n",
    "    titles = load_titles(pg_url)\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(titles), specials=['<pad>', '<unk>'])\n",
    "    encoded_tensor = encode_titles(titles, vocab)\n",
    "\n",
    "    print(\"Vocab size:\", len(vocab))\n",
    "    print(\"Example tensor shape:\", encoded_tensor.shape)\n",
    "    print(\"First encoded title:\", encoded_tensor[0])\n",
    "    print(tokenize(\"This is a test! With punctuation?\"))\n",
    "    # Output: ['thi', 'is', 'a', 'test', '!', 'with', 'punctuat', '?']\n",
    "    return encoded_tensor, vocab\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pg_url = \"postgresql://sy91dhb:g5t49ao@178.156.142.230:5432/hd64m1ki\"\n",
    "    encoded_titles, vocab = main(pg_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".hacker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
